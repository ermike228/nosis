name: NOSIS Performance & Load Testing

on:
  workflow_dispatch:
    inputs:
      target_env:
        description: "Target environment (staging | production)"
        required: true
        default: "staging"
      test_profile:
        description: "Load profile (smoke | load | stress)"
        required: true
        default: "load"
      duration_seconds:
        description: "Test duration in seconds"
        required: true
        default: "300"

  workflow_run:
    workflows:
      - "NOSIS Deploy to Staging"
    types:
      - completed

env:
  STAGING_API_URL: "https://staging.nosis.ai"
  PROD_API_URL: "https://api.nosis.ai"
  MAX_P95_LATENCY_MS: "1200"
  MAX_ERROR_RATE: "1.0"
  PYTHON_VERSION: "3.11"

jobs:
  #########################################################
  # JOB 1 — PRE-FLIGHT VALIDATION
  #########################################################
  validate:
    name: Validate performance test config
    runs-on: ubuntu-latest

    outputs:
      api_url: ${{ steps.env.outputs.api }}

    steps:
      - name: Resolve API URL
        id: env
        run: |
          if [[ "${{ inputs.target_env }}" == "production" ]]; then
            echo "api=${{ env.PROD_API_URL }}" >> $GITHUB_OUTPUT
          else
            echo "api=${{ env.STAGING_API_URL }}" >> $GITHUB_OUTPUT
          fi

      - name: Validate profile
        run: |
          if [[ "${{ inputs.test_profile }}" != "smoke" && \
                "${{ inputs.test_profile }}" != "load" && \
                "${{ inputs.test_profile }}" != "stress" ]]; then
            echo "Invalid test profile"
            exit 1
          fi

  #########################################################
  # JOB 2 — LOAD GENERATION
  #########################################################
  load_test:
    name: Run performance tests
    runs-on: ubuntu-latest
    needs: validate

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install load-test dependencies
        run: |
          pip install httpx asyncio rich numpy pandas

      - name: Execute load test
        env:
          API_URL: ${{ needs.validate.outputs.api_url }}
          PROFILE: ${{ inputs.test_profile }}
          DURATION: ${{ inputs.duration_seconds }}
        run: |
          python performance/run_load_test.py \
            --api-url $API_URL \
            --profile $PROFILE \
            --duration $DURATION \
            --output performance/results.json

      - name: Upload raw results
        uses: actions/upload-artifact@v4
        with:
          name: perf-results
          path: performance/results.json

  #########################################################
  # JOB 3 — ANALYSIS & QUALITY GATE
  #########################################################
  analyze:
    name: Analyze performance results
    runs-on: ubuntu-latest
    needs: load_test

    steps:
      - uses: actions/checkout@v4

      - name: Install analysis dependencies
        run: |
          pip install numpy pandas rich

      - name: Evaluate latency & error rate
        run: |
          python performance/analyze_results.py \
            --results performance/results.json \
            --max-p95 ${{ env.MAX_P95_LATENCY_MS }} \
            --max-error-rate ${{ env.MAX_ERROR_RATE }}

  #########################################################
  # JOB 4 — AUTO-BLOCK OR APPROVE
  #########################################################
  gate:
    name: Performance gate
    runs-on: ubuntu-latest
    needs: analyze

    steps:
      - name: Approve performance quality
        run: |
          echo "Performance metrics are within acceptable thresholds."
          echo "Deployment is allowed."
